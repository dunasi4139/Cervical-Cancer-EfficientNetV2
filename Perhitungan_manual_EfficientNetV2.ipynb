{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R4aEkj79VG_9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"gambar-prediksi.jpg\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9962,  1.9962,  0.0823, -0.7121, -0.2968],\n",
      "         [ 1.0393,  1.3101, -0.3690, -0.8204, -0.6038],\n",
      "         [ 1.6892,  1.3462, -0.2607, -1.0732, -1.0010],\n",
      "         [ 1.6892,  1.5448,  0.3893, -0.8565, -0.9468],\n",
      "         [ 1.0573,  0.7323,  0.2268, -0.4413, -0.7121]],\n",
      "\n",
      "        [[-0.2968,  0.2268, -0.0441,  0.2990,  0.6240],\n",
      "         [ 0.2990,  1.2198,  0.4976,  0.3893, -0.0079],\n",
      "         [ 1.8698,  1.5990,  0.7323,  0.1546, -0.1704],\n",
      "         [ 1.8698,  1.6712,  1.0573,  0.4073,  0.3532],\n",
      "         [ 1.2740,  1.2198,  1.1656,  0.7143,  0.3893]],\n",
      "\n",
      "        [[ 0.5518,  0.9851,  0.7684,  1.0212,  1.2920],\n",
      "         [ 1.2559,  1.7976,  1.2740,  1.2017,  0.9490],\n",
      "         [ 2.2489,  2.0864,  1.4906,  1.0393,  0.8045],\n",
      "         [ 2.2851,  2.2128,  1.7434,  1.2017,  1.1837],\n",
      "         [ 2.0684,  1.9781,  1.8156,  1.4545,  1.2920]]])\n",
      "tensor([[[[ 2.,  2.,  1.,  0.,  0.],\n",
      "          [ 2.,  2.,  0.,  0.,  0.],\n",
      "          [ 2.,  2.,  0., -1., -1.],\n",
      "          [ 2.,  2.,  1.,  0.,  0.],\n",
      "          [ 2.,  1.,  1.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  1.,  0.,  1.,  1.],\n",
      "          [ 1.,  2.,  1.,  1.,  0.],\n",
      "          [ 2.,  2.,  1.,  1.,  0.],\n",
      "          [ 2.,  2.,  2.,  1.,  1.],\n",
      "          [ 2.,  2.,  2.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  2.,  2.],\n",
      "          [ 2.,  2.,  2.,  2.,  1.],\n",
      "          [ 3.,  3.,  2.,  2.,  1.],\n",
      "          [ 3.,  3.,  2.,  2.,  2.],\n",
      "          [ 3.,  2.,  2.,  2.,  2.]]]])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.488,), (0.2172,))\n",
    "])\n",
    "\n",
    "transformed_image = transform(image)\n",
    "\n",
    "print(transformed_image)\n",
    "transformed_image_bulat = np.ceil(transformed_image)\n",
    "X = torch.tensor(np.where(transformed_image_bulat == -0, 0, transformed_image_bulat))\n",
    "X = X.unsqueeze(0)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7tRsTYZyaHW",
    "outputId": "53434871-1270-44c3-a3a8-3533b6d50f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "NgmqeeXZyb44"
   },
   "outputs": [],
   "source": [
    "class MYEfficientNetV2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                            out_channels=1,\n",
    "                            kernel_size=3,\n",
    "                            bias=False)\n",
    "    self.conv1.weight = nn.Parameter(torch.tensor(\n",
    "        [[[[0, -1, 1],\n",
    "           [1, 2, -1],\n",
    "           [2, -1, -2]],\n",
    "          [[2, -1, 0],\n",
    "           [1, 0, -2],\n",
    "           [0, -1, -1]],\n",
    "          [[-1, 0, -1],\n",
    "           [1, -1, 2],\n",
    "           [1, 1, -1]]]], dtype = torch.float32, requires_grad=True))\n",
    "    self.batchnorm = nn.BatchNorm2d(1, affine=True)\n",
    "    self.activation = nn.SiLU()\n",
    "    self.pointwise_conv = nn.Conv2d(\n",
    "            in_channels = 1,\n",
    "            out_channels = 3,\n",
    "            kernel_size=1,\n",
    "            bias=False,\n",
    "        )\n",
    "    self.pointwise_conv.weight = nn.Parameter(torch.tensor(\n",
    "        [[[[0.5]]],\n",
    "           [[[0.2]]],\n",
    "           [[[0.8]]]], dtype = torch.float32, requires_grad=True))\n",
    "\n",
    "    self.batchnorm2 = nn.BatchNorm2d(3, affine=True)\n",
    "\n",
    "    self.depthwise = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, padding_mode='zeros',\n",
    "                                   groups=3, bias=False)\n",
    "    \n",
    "    self.depthwise.weight = nn.Parameter(torch.tensor(\n",
    "            [[[[0, -1, 1], [1, 2, -1], [2, -1, -2]]],\n",
    "             [[[2, -1, 0], [1, 0, -2], [0, -1, -1]]],\n",
    "             [[[-1, 0, -1], [1, -1, 2], [1, 1, -1]]]], dtype=torch.float32, requires_grad=True))\n",
    "    \n",
    "    self.seblock = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3, 3, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    mat2 = torch.tensor([[0.2089591267, 0.2089591267, 0.2089591267],\n",
    "                        [0.2096759506, 0.2096759506, 0.2096759506],\n",
    "                        [0.2117456203, 0.2117456203, 0.2117456203]], dtype=torch.float32)\n",
    "    self.seblock[2].weight.data = nn.Parameter(mat2)\n",
    "\n",
    "    self.fc = nn.Linear(in_features=27,\n",
    "                        out_features=3,\n",
    "                        bias=False)\n",
    "\n",
    "    self.fc.weight = nn.Parameter(torch.tensor(\n",
    "        [[0, -1, 1, 1, 2, -1, 2, -1, -2],\n",
    "         [2, -1, 0, 1, 0, -2, 0, -1, -1],\n",
    "         [-1, 0, -1, 1, -1, 2, 1, 1, -1]], dtype = torch.float32, requires_grad=True))\n",
    "    \n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, X):\n",
    "    x = self.conv1(X)\n",
    "    print(\"Convolusi:\\n\", x)\n",
    "    x = self.batchnorm(x)\n",
    "    print(\"Batch Normalization:\\n\", x)\n",
    "    x = self.activation(x)\n",
    "    print(\"Swish:\\n\", x)\n",
    "\n",
    "    x = self.pointwise_conv(x)\n",
    "    print(\"Pointwise Convolution:\\n\", x)\n",
    "    x = self.batchnorm2(x)\n",
    "    print(\"Pointwise Convolution Batch Normalization:\\n\", x)\n",
    "    x = self.activation(x)\n",
    "    print(\"Pointwise Convolution Swish:\\n\", x)\n",
    "    x = self.depthwise(x)\n",
    "    print(\"Depthwise:\\n\", x)\n",
    "    x = self.batchnorm2(x)\n",
    "    print(\"Depthwise Batch Normalization:\\n\", x)\n",
    "    x = self.activation(x)\n",
    "    print(\"Depthwise Swish:\\n\", x)\n",
    "    se_weights = self.seblock(x)\n",
    "    x = x * se_weights[:, :, None, None]\n",
    "    print(\"SEBlok:\\n\", x)\n",
    "    \n",
    "    hasil = torch.flatten(x)\n",
    "    print(\"Flatten:\\n\", hasil)\n",
    "    x = self.fc(x.view(3, 9))\n",
    "    print(\"Result Neural Network:\\n\", x)\n",
    "    x = self.softmax(x)\n",
    "    print(\"Softmax:\\n\", x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qv9UiC2I0Isa",
    "outputId": "3d527c2a-19d5-4bb8-c64c-a09557402c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolusi:\n",
      " tensor([[[[ 8., 11.,  4.],\n",
      "          [ 4., 10.,  2.],\n",
      "          [ 2.,  6.,  5.]]]], grad_fn=<ConvolutionBackward0>)\n",
      "Batch Normalization:\n",
      " tensor([[[[ 0.7207,  1.6938, -0.5766],\n",
      "          [-0.5766,  1.3694, -1.2253],\n",
      "          [-1.2253,  0.0721, -0.2523]]]], grad_fn=<NativeBatchNormBackward0>)\n",
      "Swish:\n",
      " tensor([[[[ 0.4849,  1.4308, -0.2074],\n",
      "          [-0.2074,  1.0918, -0.2781],\n",
      "          [-0.2781,  0.0373, -0.1103]]]], grad_fn=<SiluBackward0>)\n",
      "Pointwise Convolution:\n",
      " tensor([[[[ 0.2425,  0.7154, -0.1037],\n",
      "          [-0.1037,  0.5459, -0.1391],\n",
      "          [-0.1391,  0.0187, -0.0552]],\n",
      "\n",
      "         [[ 0.0970,  0.2862, -0.0415],\n",
      "          [-0.0415,  0.2184, -0.0556],\n",
      "          [-0.0556,  0.0075, -0.0221]],\n",
      "\n",
      "         [[ 0.3879,  1.1446, -0.1659],\n",
      "          [-0.1659,  0.8735, -0.2225],\n",
      "          [-0.2225,  0.0299, -0.0882]]]], grad_fn=<ConvolutionBackward0>)\n",
      "Pointwise Convolution Batch Normalization:\n",
      " tensor([[[[ 0.4405,  2.0023, -0.7027],\n",
      "          [-0.7027,  1.4427, -0.8195],\n",
      "          [-0.8195, -0.2986, -0.5424]],\n",
      "\n",
      "         [[ 0.4403,  2.0018, -0.7025],\n",
      "          [-0.7025,  1.4423, -0.8193],\n",
      "          [-0.8193, -0.2985, -0.5422]],\n",
      "\n",
      "         [[ 0.4405,  2.0024, -0.7028],\n",
      "          [-0.7028,  1.4427, -0.8196],\n",
      "          [-0.8196, -0.2986, -0.5424]]]], grad_fn=<NativeBatchNormBackward0>)\n",
      "Pointwise Convolution Swish:\n",
      " tensor([[[[ 0.2680,  1.7642, -0.2327],\n",
      "          [-0.2327,  1.1669, -0.2507],\n",
      "          [-0.2507, -0.1272, -0.1994]],\n",
      "\n",
      "         [[ 0.2679,  1.7635, -0.2327],\n",
      "          [-0.2327,  1.1665, -0.2506],\n",
      "          [-0.2506, -0.1271, -0.1994]],\n",
      "\n",
      "         [[ 0.2680,  1.7642, -0.2328],\n",
      "          [-0.2328,  1.1670, -0.2507],\n",
      "          [-0.2507, -0.1272, -0.1994]]]], grad_fn=<SiluBackward0>)\n",
      "Depthwise:\n",
      " tensor([[[[-3.3293,  2.8979,  3.8832],\n",
      "          [ 0.3687,  0.3795,  0.8434],\n",
      "          [ 1.0255, -1.7232, -0.2753]],\n",
      "\n",
      "         [[-4.4609, -0.1826,  2.0142],\n",
      "          [-2.2231, -0.6327,  5.1256],\n",
      "          [ 0.4870, -1.4839,  2.4565]],\n",
      "\n",
      "         [[ 1.8607, -0.7768,  2.9133],\n",
      "          [ 0.6790, -2.1147, -0.6731],\n",
      "          [-1.1707, -0.0389, -1.0948]]]], grad_fn=<ConvolutionBackward0>)\n",
      "Depthwise Batch Normalization:\n",
      " tensor([[[[-1.8450,  1.1932,  1.6739],\n",
      "          [-0.0408, -0.0355,  0.1908],\n",
      "          [ 0.2797, -1.0614, -0.3550]],\n",
      "\n",
      "         [[-1.7194, -0.1144,  0.7098],\n",
      "          [-0.8799, -0.2832,  1.8771],\n",
      "          [ 0.1368, -0.6026,  0.8757]],\n",
      "\n",
      "         [[ 1.2638, -0.4842,  1.9614],\n",
      "          [ 0.4806, -1.3709, -0.4155],\n",
      "          [-0.7452,  0.0049, -0.6949]]]], grad_fn=<NativeBatchNormBackward0>)\n",
      "Depthwise Swish:\n",
      " tensor([[[[-0.2518,  0.9156,  1.4096],\n",
      "          [-0.0200, -0.0174,  0.1045],\n",
      "          [ 0.1593, -0.2728, -0.1463]],\n",
      "\n",
      "         [[-0.2613, -0.0539,  0.4758],\n",
      "          [-0.2580, -0.1217,  1.6280],\n",
      "          [ 0.0731, -0.2132,  0.6182]],\n",
      "\n",
      "         [[ 0.9854, -0.1846,  1.7195],\n",
      "          [ 0.2970, -0.2776, -0.1652],\n",
      "          [-0.2399,  0.0024, -0.2314]]]], grad_fn=<SiluBackward0>)\n",
      "SEBlok:\n",
      " tensor([[[[-0.1342,  0.4879,  0.7512],\n",
      "          [-0.0106, -0.0093,  0.0557],\n",
      "          [ 0.0849, -0.1454, -0.0780]],\n",
      "\n",
      "         [[-0.1392, -0.0287,  0.2536],\n",
      "          [-0.1375, -0.0649,  0.8677],\n",
      "          [ 0.0390, -0.1136,  0.3295]],\n",
      "\n",
      "         [[ 0.5255, -0.0985,  0.9171],\n",
      "          [ 0.1584, -0.1480, -0.0881],\n",
      "          [-0.1279,  0.0013, -0.1234]]]], grad_fn=<MulBackward0>)\n",
      "Flatten:\n",
      " tensor([-0.1342,  0.4879,  0.7512, -0.0106, -0.0093,  0.0557,  0.0849, -0.1454,\n",
      "        -0.0780, -0.1392, -0.0287,  0.2536, -0.1375, -0.0649,  0.8677,  0.0390,\n",
      "        -0.1136,  0.3295,  0.5255, -0.0985,  0.9171,  0.1584, -0.1480, -0.0881,\n",
      "        -0.1279,  0.0013, -0.1234], grad_fn=<ReshapeAliasBackward0>)\n",
      "Result Neural Network:\n",
      " tensor([[ 0.6494, -0.6549, -0.4895],\n",
      "        [-1.3201, -2.3386,  1.1442],\n",
      "        [ 0.9556,  1.6062, -1.3156]], grad_fn=<MmBackward0>)\n",
      "Softmax:\n",
      " tensor([[0.6283, 0.1705, 0.2012],\n",
      "        [0.0762, 0.0275, 0.8962],\n",
      "        [0.3311, 0.6347, 0.0342]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MYEfficientNetV2()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "output = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:\n",
      " tensor(0.7580, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "target = torch.tensor([[1, 0, 0],\n",
    "                       [0, 0, 1],\n",
    "                       [0, 1, 0]])\n",
    "loss = criterion(output, torch.argmax(target, dim=1))\n",
    "print(\"Loss:\\n\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "vVkGan1QbcxA",
    "outputId": "307c9949-2fdb-4270-9068-51b76edda1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Connected grad:\n",
      " tensor([[ 0.0441, -0.0455,  0.0115,  0.0088, -0.0111,  0.0093, -0.0147,  0.0088,\n",
      "          0.0049],\n",
      "        [-0.0466,  0.0248, -0.0420, -0.0138,  0.0106,  0.0159,  0.0132, -0.0062,\n",
      "          0.0095],\n",
      "        [ 0.0025,  0.0207,  0.0304,  0.0050,  0.0005, -0.0252,  0.0014, -0.0026,\n",
      "         -0.0144]])\n",
      "new weight FC:\n",
      " Parameter containing:\n",
      "tensor([[-4.4088e-05, -9.9995e-01,  9.9999e-01,  9.9999e-01,  2.0000e+00,\n",
      "         -1.0000e+00,  2.0000e+00, -1.0000e+00, -2.0000e+00],\n",
      "        [ 2.0000e+00, -1.0000e+00,  4.1965e-05,  1.0000e+00, -1.0576e-05,\n",
      "         -2.0000e+00, -1.3238e-05, -9.9999e-01, -1.0000e+00],\n",
      "        [-1.0000e+00, -2.0735e-05, -1.0000e+00,  1.0000e+00, -1.0000e+00,\n",
      "          2.0000e+00,  1.0000e+00,  1.0000e+00, -9.9999e-01]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(\"Fully Connected grad:\\n\", model.fc.weight.grad)\n",
    "print(\"new weight FC:\\n\", model.fc.weight)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
